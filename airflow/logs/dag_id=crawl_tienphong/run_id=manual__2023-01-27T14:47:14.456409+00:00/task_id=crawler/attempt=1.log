[2023-01-27T14:47:17.200+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: crawl_tienphong.crawler manual__2023-01-27T14:47:14.456409+00:00 [queued]>
[2023-01-27T14:47:17.214+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: crawl_tienphong.crawler manual__2023-01-27T14:47:14.456409+00:00 [queued]>
[2023-01-27T14:47:17.214+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-01-27T14:47:17.214+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 4
[2023-01-27T14:47:17.214+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-01-27T14:47:17.237+0000] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): crawler> on 2023-01-27 14:47:14.456409+00:00
[2023-01-27T14:47:17.243+0000] {standard_task_runner.py:55} INFO - Started process 4209 to run task
[2023-01-27T14:47:17.246+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'crawl_tienphong', 'crawler', 'manual__2023-01-27T14:47:14.456409+00:00', '--job-id', '428', '--raw', '--subdir', 'DAGS_FOLDER/crawl_tienphong.py', '--cfg-path', '/tmp/tmpbvd_93gw']
[2023-01-27T14:47:17.247+0000] {standard_task_runner.py:83} INFO - Job 428: Subtask crawler
[2023-01-27T14:47:17.322+0000] {task_command.py:388} INFO - Running <TaskInstance: crawl_tienphong.crawler manual__2023-01-27T14:47:14.456409+00:00 [running]> on host 9be4ecca8506
[2023-01-27T14:47:17.429+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=phukaioh
AIRFLOW_CTX_DAG_ID=crawl_tienphong
AIRFLOW_CTX_TASK_ID=crawler
AIRFLOW_CTX_EXECUTION_DATE=2023-01-27T14:47:14.456409+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-01-27T14:47:14.456409+00:00
[2023-01-27T14:47:17.430+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2023-01-27T14:47:17.431+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'cd /opt/project/ && ls -la && pip install scrapy && scrapy version ']
[2023-01-27T14:47:17.444+0000] {subprocess.py:86} INFO - Output:
[2023-01-27T14:47:17.449+0000] {subprocess.py:93} INFO - total 36
[2023-01-27T14:47:17.449+0000] {subprocess.py:93} INFO - drwxrwxr-x 5 default 1001 4096 Jan 27 14:40 .
[2023-01-27T14:47:17.449+0000] {subprocess.py:93} INFO - drwxr-xr-x 1 root    root 4096 Jan 27 13:53 ..
[2023-01-27T14:47:17.449+0000] {subprocess.py:93} INFO - drwxrwxr-x 4 default 1001 4096 Jan 26 03:12 crawler
[2023-01-27T14:47:17.450+0000] {subprocess.py:93} INFO - drwxrwxr-x 2 default 1001 4096 Jan 27 13:29 data
[2023-01-27T14:47:17.450+0000] {subprocess.py:93} INFO - -rw-rw-r-- 1 default 1001   69 Jan 27 13:13 run_crawl_tienphong.sh
[2023-01-27T14:47:17.450+0000] {subprocess.py:93} INFO - -rw-rw-r-- 1 default 1001  257 Jan 26 03:08 scrapy.cfg
[2023-01-27T14:47:17.450+0000] {subprocess.py:93} INFO - drwxrwxr-x 2 default 1001 4096 Jan 27 13:29 source
[2023-01-27T14:47:17.450+0000] {subprocess.py:93} INFO - -rw-rw-r-- 1 default 1001    6 Jan 27 13:16 test.sh
[2023-01-27T14:47:18.654+0000] {subprocess.py:93} INFO - Defaulting to user installation because normal site-packages is not writeable
[2023-01-27T14:47:19.325+0000] {subprocess.py:93} INFO - Collecting scrapy
[2023-01-27T14:47:19.329+0000] {subprocess.py:93} INFO -   Using cached Scrapy-2.7.1-py2.py3-none-any.whl (271 kB)
[2023-01-27T14:47:19.771+0000] {subprocess.py:93} INFO - Collecting queuelib>=1.4.2
[2023-01-27T14:47:20.101+0000] {subprocess.py:93} INFO -   Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)
[2023-01-27T14:47:20.216+0000] {subprocess.py:93} INFO - Collecting w3lib>=1.17.0
[2023-01-27T14:47:20.220+0000] {subprocess.py:93} INFO -   Using cached w3lib-2.1.1-py3-none-any.whl (21 kB)
[2023-01-27T14:47:20.321+0000] {subprocess.py:93} INFO - Collecting protego>=0.1.15
[2023-01-27T14:47:20.324+0000] {subprocess.py:93} INFO -   Using cached Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)
[2023-01-27T14:47:20.401+0000] {subprocess.py:93} INFO - Collecting PyDispatcher>=2.0.5
[2023-01-27T14:47:20.404+0000] {subprocess.py:93} INFO -   Using cached PyDispatcher-2.0.6.tar.gz (38 kB)
[2023-01-27T14:47:20.425+0000] {subprocess.py:93} INFO -   Preparing metadata (setup.py): started
[2023-01-27T14:47:21.651+0000] {subprocess.py:93} INFO -   Preparing metadata (setup.py): finished with status 'done'
[2023-01-27T14:47:21.655+0000] {subprocess.py:93} INFO - Requirement already satisfied: zope.interface>=5.1.0 in /home/***/.local/lib/python3.7/site-packages (from scrapy) (5.5.2)
[2023-01-27T14:47:21.746+0000] {subprocess.py:93} INFO - Collecting itemadapter>=0.1.0
[2023-01-27T14:47:21.750+0000] {subprocess.py:93} INFO -   Using cached itemadapter-0.7.0-py3-none-any.whl (10 kB)
[2023-01-27T14:47:21.753+0000] {subprocess.py:93} INFO - Requirement already satisfied: cryptography>=3.3 in /home/***/.local/lib/python3.7/site-packages (from scrapy) (38.0.4)
[2023-01-27T14:47:21.754+0000] {subprocess.py:93} INFO - Requirement already satisfied: packaging in /home/***/.local/lib/python3.7/site-packages (from scrapy) (21.3)
[2023-01-27T14:47:21.837+0000] {subprocess.py:93} INFO - Collecting service-identity>=18.1.0
[2023-01-27T14:47:21.894+0000] {subprocess.py:93} INFO -   Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)
[2023-01-27T14:47:22.038+0000] {subprocess.py:93} INFO - Collecting Twisted>=18.9.0
[2023-01-27T14:47:22.102+0000] {subprocess.py:93} INFO -   Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)
[2023-01-27T14:47:23.073+0000] {subprocess.py:93} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 3.2 MB/s eta 0:00:00
[2023-01-27T14:47:23.412+0000] {subprocess.py:93} INFO - Collecting itemloaders>=1.0.1
[2023-01-27T14:47:23.474+0000] {subprocess.py:93} INFO -   Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)
[2023-01-27T14:47:23.486+0000] {subprocess.py:93} INFO - Requirement already satisfied: pyOpenSSL>=21.0.0 in /home/***/.local/lib/python3.7/site-packages (from scrapy) (22.1.0)
[2023-01-27T14:47:23.487+0000] {subprocess.py:93} INFO - Requirement already satisfied: lxml>=4.3.0 in /home/***/.local/lib/python3.7/site-packages (from scrapy) (4.9.2)
[2023-01-27T14:47:23.585+0000] {subprocess.py:93} INFO - Collecting parsel>=1.5.0
[2023-01-27T14:47:23.588+0000] {subprocess.py:93} INFO -   Using cached parsel-1.7.0-py2.py3-none-any.whl (14 kB)
[2023-01-27T14:47:23.590+0000] {subprocess.py:93} INFO - Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from scrapy) (57.5.0)
[2023-01-27T14:47:23.691+0000] {subprocess.py:93} INFO - Collecting tldextract
[2023-01-27T14:47:23.694+0000] {subprocess.py:93} INFO -   Using cached tldextract-3.4.0-py3-none-any.whl (93 kB)
[2023-01-27T14:47:23.805+0000] {subprocess.py:93} INFO - Collecting cssselect>=0.9.1
[2023-01-27T14:47:23.809+0000] {subprocess.py:93} INFO -   Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)
[2023-01-27T14:47:23.857+0000] {subprocess.py:93} INFO - Requirement already satisfied: cffi>=1.12 in /home/***/.local/lib/python3.7/site-packages (from cryptography>=3.3->scrapy) (1.15.1)
[2023-01-27T14:47:23.870+0000] {subprocess.py:93} INFO - Requirement already satisfied: jmespath>=0.9.5 in /home/***/.local/lib/python3.7/site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)
[2023-01-27T14:47:23.902+0000] {subprocess.py:93} INFO - Requirement already satisfied: six in /home/***/.local/lib/python3.7/site-packages (from protego>=0.1.15->scrapy) (1.16.0)
[2023-01-27T14:47:23.954+0000] {subprocess.py:93} INFO - Requirement already satisfied: pyasn1 in /home/***/.local/lib/python3.7/site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)
[2023-01-27T14:47:23.956+0000] {subprocess.py:93} INFO - Requirement already satisfied: attrs>=19.1.0 in /home/***/.local/lib/python3.7/site-packages (from service-identity>=18.1.0->scrapy) (22.2.0)
[2023-01-27T14:47:23.957+0000] {subprocess.py:93} INFO - Requirement already satisfied: pyasn1-modules in /home/***/.local/lib/python3.7/site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)
[2023-01-27T14:47:24.475+0000] {subprocess.py:93} INFO - Collecting hyperlink>=17.1.1
[2023-01-27T14:47:24.545+0000] {subprocess.py:93} INFO -   Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)
[2023-01-27T14:47:24.583+0000] {subprocess.py:93} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.6/74.6 kB 2.9 MB/s eta 0:00:00
[2023-01-27T14:47:24.588+0000] {subprocess.py:93} INFO - Requirement already satisfied: typing-extensions>=3.6.5 in /home/***/.local/lib/python3.7/site-packages (from Twisted>=18.9.0->scrapy) (4.4.0)
[2023-01-27T14:47:24.680+0000] {subprocess.py:93} INFO - Collecting constantly>=15.1
[2023-01-27T14:47:24.744+0000] {subprocess.py:93} INFO -   Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)
[2023-01-27T14:47:24.871+0000] {subprocess.py:93} INFO - Collecting incremental>=21.3.0
[2023-01-27T14:47:24.934+0000] {subprocess.py:93} INFO -   Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)
[2023-01-27T14:47:25.051+0000] {subprocess.py:93} INFO - Collecting Automat>=0.8.0
[2023-01-27T14:47:25.114+0000] {subprocess.py:93} INFO -   Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)
[2023-01-27T14:47:25.171+0000] {subprocess.py:93} INFO - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/***/.local/lib/python3.7/site-packages (from packaging->scrapy) (3.0.9)
[2023-01-27T14:47:25.269+0000] {subprocess.py:93} INFO - Collecting requests-file>=1.4
[2023-01-27T14:47:25.330+0000] {subprocess.py:93} INFO -   Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)
[2023-01-27T14:47:25.342+0000] {subprocess.py:93} INFO - Requirement already satisfied: idna in /home/***/.local/lib/python3.7/site-packages (from tldextract->scrapy) (3.4)
[2023-01-27T14:47:25.353+0000] {subprocess.py:93} INFO - Requirement already satisfied: requests>=2.1.0 in /home/***/.local/lib/python3.7/site-packages (from tldextract->scrapy) (2.28.2)
[2023-01-27T14:47:25.354+0000] {subprocess.py:93} INFO - Requirement already satisfied: filelock>=3.0.8 in /home/***/.local/lib/python3.7/site-packages (from tldextract->scrapy) (3.9.0)
[2023-01-27T14:47:25.469+0000] {subprocess.py:93} INFO - Requirement already satisfied: pycparser in /home/***/.local/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.21)
[2023-01-27T14:47:25.580+0000] {subprocess.py:93} INFO - Requirement already satisfied: certifi>=2017.4.17 in /home/***/.local/lib/python3.7/site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)
[2023-01-27T14:47:25.583+0000] {subprocess.py:93} INFO - Requirement already satisfied: charset-normalizer<4,>=2 in /home/***/.local/lib/python3.7/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.1.1)
[2023-01-27T14:47:25.585+0000] {subprocess.py:93} INFO - Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/***/.local/lib/python3.7/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.14)
[2023-01-27T14:47:25.764+0000] {subprocess.py:93} INFO - Building wheels for collected packages: PyDispatcher
[2023-01-27T14:47:25.765+0000] {subprocess.py:93} INFO -   Building wheel for PyDispatcher (setup.py): started
[2023-01-27T14:47:27.272+0000] {subprocess.py:93} INFO -   Building wheel for PyDispatcher (setup.py): finished with status 'done'
[2023-01-27T14:47:27.273+0000] {subprocess.py:93} INFO -   Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11959 sha256=9b5713b95190243269053dd6627e82cbb1e69366266705dca5968db4ec8d0d31
[2023-01-27T14:47:27.273+0000] {subprocess.py:93} INFO -   Stored in directory: /home/***/.cache/pip/wheels/b6/96/2a/396383bdacebef742195f6cf5210a80022ec031fc914fc4308
[2023-01-27T14:47:27.276+0000] {subprocess.py:93} INFO - Successfully built PyDispatcher
[2023-01-27T14:47:37.989+0000] {subprocess.py:93} INFO - Installing collected packages: PyDispatcher, incremental, constantly, w3lib, queuelib, protego, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy
[2023-01-27T14:47:42.782+0000] {subprocess.py:93} INFO - Successfully installed Automat-22.10.0 PyDispatcher-2.0.6 Twisted-22.10.0 constantly-15.1.0 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 parsel-1.7.0 protego-0.2.1 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.7.1 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.1.1
[2023-01-27T14:47:45.024+0000] {subprocess.py:93} INFO - Scrapy 2.7.1
[2023-01-27T14:47:45.168+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2023-01-27T14:47:45.231+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=crawl_tienphong, task_id=crawler, execution_date=20230127T144714, start_date=20230127T144717, end_date=20230127T144745
[2023-01-27T14:47:45.308+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2023-01-27T14:47:45.338+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
